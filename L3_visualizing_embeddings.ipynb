{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from utils import authenticate\n",
        "credentials, PROJECT_ID = authenticate() #Get credentials and project ID"
      ],
      "metadata": {
        "id": "sn_EL8DFNgMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REGION = 'us-central1'"
      ],
      "metadata": {
        "id": "5uiRNJOaKqD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enter project details"
      ],
      "metadata": {
        "id": "yI1jGZaMLHpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and initialize the Vertex AI Python SDK\n",
        "\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID,\n",
        "              location=REGION,\n",
        "              credentials = credentials)"
      ],
      "metadata": {
        "id": "sHwrhIGoK1dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings capture meaning"
      ],
      "metadata": {
        "id": "VNYF1A_vLPnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_1 = \"Missing flamingo discovered at swimming pool\"\n",
        "\n",
        "in_2 = \"Sea otter spotted on surfboard by beach\"\n",
        "\n",
        "in_3 = \"Baby panda enjoys boat ride\"\n",
        "\n",
        "\n",
        "in_4 = \"Breakfast themed food truck beloved by all!\"\n",
        "\n",
        "in_5 = \"New curry restaurant aims to please!\"\n",
        "\n",
        "\n",
        "in_6 = \"Python developers are wonderful people\"\n",
        "\n",
        "in_7 = \"TypeScript, C++ or Java? All are great!\"\n",
        "\n",
        "\n",
        "input_text_lst_news = [in_1, in_2, in_3, in_4, in_5, in_6, in_7]"
      ],
      "metadata": {
        "id": "77COs17qK2o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "\n",
        "embedding_model = TextEmbeddingModel.from_pretrained(\n",
        "    \"textembedding-gecko@001\")"
      ],
      "metadata": {
        "id": "xDlnnvg1K3MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Get embeddings for all pieces of text.\n",
        "*   Store them in a 2D NumPy array (one row for each embedding).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UHKyCFHtK33j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "for input_text in input_text_lst_news:\n",
        "    emb = embedding_model.get_embeddings(\n",
        "        [input_text])[0].values\n",
        "    embeddings.append(emb)\n",
        "\n",
        "embeddings_array = np.array(embeddings)"
      ],
      "metadata": {
        "id": "pZB-CpKnK4xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape: \" + str(embeddings_array.shape))\n",
        "print(embeddings_array)"
      ],
      "metadata": {
        "id": "y8MBqrYCLrQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce embeddings from 768 to 2 dimensions for visualization"
      ],
      "metadata": {
        "id": "MzcrgpJRLvn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use principal component analysis (PCA)"
      ],
      "metadata": {
        "id": "u7_jnCl9L55i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform PCA for 2D visualization\n",
        "PCA_model = PCA(n_components = 2)\n",
        "PCA_model.fit(embeddings_array)\n",
        "new_values = PCA_model.transform(embeddings_array)"
      ],
      "metadata": {
        "id": "Hsm-JO9BL9Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape: \" + str(new_values.shape))\n",
        "print(new_values)"
      ],
      "metadata": {
        "id": "nhnldZz9MBdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import mplcursors\n",
        "%matplotlib ipympl\n",
        "\n",
        "from utils import plot_2D\n",
        "plot_2D(new_values[:,0], new_values[:,1], input_text_lst_news)"
      ],
      "metadata": {
        "id": "F0RcmXX1MBry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings and Similarity"
      ],
      "metadata": {
        "id": "NPkp1EosMLQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Plot a heat map to compare the embeddings of sentences that are similar and sentences that are dissimilar\n",
        "\n"
      ],
      "metadata": {
        "id": "c2JXJI_nMLbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_1 = \"\"\"He couldnâ€™t desert\n",
        "          his post at the power plant.\"\"\"\n",
        "\n",
        "in_2 = \"\"\"The power plant needed\n",
        "          him at the time.\"\"\"\n",
        "\n",
        "in_3 = \"\"\"Cacti are able to\n",
        "          withstand dry environments.\"\"\"\n",
        "\n",
        "in_4 = \"\"\"Desert plants can\n",
        "          survive droughts.\"\"\"\n",
        "\n",
        "input_text_lst_sim = [in_1, in_2, in_3, in_4]"
      ],
      "metadata": {
        "id": "AL4mOSMUMKL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "for input_text in input_text_lst_sim:\n",
        "    emb = embedding_model.get_embeddings([input_text])[0].values\n",
        "    embeddings.append(emb)\n",
        "\n",
        "embeddings_array = np.array(embeddings)"
      ],
      "metadata": {
        "id": "UtELR3IxMqvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import plot_heatmap\n",
        "\n",
        "y_labels = input_text_lst_sim\n",
        "\n",
        "# Plot the heatmap\n",
        "plot_heatmap(embeddings_array, y_labels = y_labels, title = \"Embeddings Heatmap\")"
      ],
      "metadata": {
        "id": "5jVls0XRMq-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute cosine similarity**"
      ],
      "metadata": {
        "id": "FDxEuZHnM7Xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The `cosine_similarity` function expects a 2D array, which is why we'll wrap each embedding list inside another list.\n",
        "*   You can verify that sentence 1 and 2 have a higher similarity compared to sentence 1 and 4, even though sentence 1 and 4 both have the words \"desert\" and \"plant\".\n",
        "\n"
      ],
      "metadata": {
        "id": "teEZs3xXNFgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "s9gyckIrM-7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare(embeddings,idx1,idx2):\n",
        "    return cosine_similarity([embeddings[idx1]],[embeddings[idx2]])"
      ],
      "metadata": {
        "id": "CrL1xdyYNRZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(in_1)\n",
        "print(in_2)\n",
        "print(compare(embeddings,0,1))"
      ],
      "metadata": {
        "id": "jo53QndTNSOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(in_1)\n",
        "print(in_4)\n",
        "print(compare(embeddings,0,3))"
      ],
      "metadata": {
        "id": "kGD-jd4MNY10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}